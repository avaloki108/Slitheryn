{
  "lmstudio_models": {
    "Llama-3.2-8X3B-MOE-Dark-Champion": {
      "path": "DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF",
      "file": "L3.2-8X3B-MOE-Dark-Champion-Inst-18.4B-uncen-ablit_D_AU-IQ4_XS.gguf",
      "estimated_size": "~12GB",
      "type": "MOE (Mixture of Experts)"
    },
    "Devstral-Small-2507": {
      "path": "lmstudio-community/Devstral-Small-2507-GGUF",
      "file": "Devstral-Small-2507-Q4_K_M.gguf",
      "estimated_size": "~3GB",
      "type": "Code-focused (small)"
    },
    "Phi-4-reasoning-plus": {
      "path": "lmstudio-community/Phi-4-reasoning-plus-GGUF",
      "file": "Phi-4-reasoning-plus-Q4_K_M.gguf",
      "estimated_size": "~8GB",
      "type": "Reasoning-focused"
    },
    "Qwen3-14B": {
      "path": "lmstudio-community/Qwen3-14B-GGUF",
      "file": "Qwen3-14B-Q4_K_M.gguf",
      "estimated_size": "~8GB",
      "type": "General purpose"
    },
    "Qwen3-30B-A3B": {
      "path": "lmstudio-community/Qwen3-30B-A3B-GGUF",
      "file": "Qwen3-30B-A3B-Q4_K_M.gguf",
      "estimated_size": "~18GB",
      "type": "Large general purpose"
    },
    "Gemma-3-12B": {
      "path": "lmstudio-community/gemma-3-12b-it-GGUF",
      "file": "gemma-3-12b-it-Q4_K_M.gguf",
      "estimated_size": "~7GB",
      "type": "Google's model"
    },
    "Absolute_Zero_Reasoner-Coder-14B": {
      "path": "mradermacher/Absolute_Zero_Reasoner-Coder-14b-GGUF",
      "file": "Absolute_Zero_Reasoner-Coder-14b.Q5_K_S.gguf",
      "estimated_size": "~10GB",
      "type": "Reasoning + Coding specialist"
    },
    "WhiteRabbitNeo-V3-7B": {
      "path": "mradermacher/WhiteRabbitNeo-V3-7B-i1-GGUF",
      "file": "WhiteRabbitNeo-V3-7B.i1-Q6_K.gguf",
      "estimated_size": "~6GB",
      "type": "WhiteRabbitNeo variant"
    }
  },
  "recommendations": {
    "security_analysis_potential": [
      "Llama-3.2-8X3B-MOE-Dark-Champion",
      "WhiteRabbitNeo-V3-7B"
    ],
    "coding_specialists": [
      "Devstral-Small-2507",
      "Absolute_Zero_Reasoner-Coder-14B"
    ],
    "reasoning_specialists": [
      "Phi-4-reasoning-plus"
    ],
    "general_purpose": [
      "Qwen3-14B",
      "Qwen3-30B-A3B",
      "Gemma-3-12B"
    ]
  },
  "test_results": null,
  "comparison_notes": "Need to load models in LM Studio to test performance"
}